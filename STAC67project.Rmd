---
title: 'STAC67 Case Study: Predictive Model For The Median Value Of Homes In Boston'
author: Group 18 / Abbas Rai 1003957104 / Calvin Chan 999940364 / Huan Wang 1001707049/ Ruotong Zheng / Andrey Zhuravlev
output:
  word_document: default
  html_notebook: default
  pdf_document: default
---
#Abstract
Buying a home is one of the most important purchase decisions in one’s life. There are many important factors for one to consider, especially the value of the home one is purchasing. In reality, the value of a home can be evaluated based on an in-depth analysis of the home’s geographical location and several other environmental and socioeconomic factors. Our team has used a plethora of statistical tests and considered several influential variables associated with this important topic in order to develop a predictive model which best explains the value of homes in the city of Boston.

#Background and Significance
The debate surrounding purchasing the "ideal" home is one that is extremely prevalent within households across the globe. People work extremely hard to save up to buy a home, making it one of the most important investments in one's lifetime. In fact, research shows that it takes the average American more than seven years to save up enough money just to deposit the down payment towards a home (Olsen, 2018). Moreover, future home buyers find themselves in an even more vulnerable position. Due to inflation and increasing price levels within the economy, there has been an increasing trend of the time needed to save up for a home in America, which has already risen by almost two years since 1988 (Olsen, 2018). The presence of these trends makes it even more important for individuals to make smart home purchases, in order to avoid facing severe economic repercussions. One of the fundamental factors which affects the value of a home is safety. A report published by the Center for American Progress concluded that “a 10% reduction in homicides would lead to a 0.83% increase in housing values the following year.” (Byloos, 2016). In addition, one must consider the presence of retail stores in the nearby area, which can actually lower the value of a house if located within close proximity (Matthews, 2006). We ultimately propose the following model to predict the median house price levels in Boston in order to provide home buyers and real estate agents with more holistic understanding of the factors which influence the value of homes and provide them with the necessary information to understand the housing market better and make better decisions overall.

#References
Olsen, S. (2018, October 22). Home Buyers Need 7.2 Years to Save Down Payments – 1.5 Years More Than in 1988. Retrieved from https://www.zillow.com/research/how-many-years-down-payment-21734/

Byloos, M. (2016). Research Crime Rates and the Impact on Home Values | Homes.com. Retrieved from https://www.homes.com/blog/2016/05/secure-new-home-research-crime-rates-impact-home-value/

Matthews, J. (2006). Retail Proximity and Residential Values or Do Nearby Stores Really Run Down Property Values?. SSRN Electronic Journal. doi: 10.2139/ssrn.989049



```{r}
#data
library(tidyverse)
housing <- read.csv("housing.proper.csv")
housing
summary(housing)
```
```{r}
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

apply(housing, 2, Mode)
```
```{r}
library(GGally)
ggcorr(housing[,1:14], name = "corr", label = TRUE)
```


```{r}
#housing <- read.csv("housing.proper.csv")
colnames(housing) <- c("X1","X2","X3","X4","X5","X6","X7",
                       "X8","X9","X10","X11","X12","X13","Y")
#head(housing)

#half the data set is choosen to create the model
#other half is for validation
set.seed(67)
housing_mod <- housing[sample(nrow(housing), 253),c(1:14)]
#housing_mod <- housing[1:253,c(1:14)]
fit_select <- lm(Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + X11 + X12 + X13, data = housing_mod)
summary(fit_select)
```

```{r}
# Stepwise Regression with function stepAIC with all 13 variables (Akaike's Information Criterion)
library(MASS)
fit_select2 = lm(Y ~ X1 + X2 + X3 + X5 + X6 + X7 + X8 + X9 + X10 + X11 + X12 + X13, data = housing_mod)
step = stepAIC(fit_select2, direction = "both")
step$anova # display results
```

```{r}
# Model validation
# ------------------------------------
# Selected model:
fit_sel <- lm(Y ~ X2 + X5 + X6 + X8 + X9 + X10 + X11 + X12 + X13, data = housing_mod)
newx <- housing[,c(2, 5, 6, 8:13)]
colnames(newx) <- c("X2","X5","X6","X8","X9","X10","X11","X12","X13")
Y_pred <- predict(fit_sel, newx)
Y_obs <- housing[,14] 
n_star <- nrow(newx)
MSPE <- sum( (Y_obs-Y_pred)^2/n_star )
MS_res <- (summary(fit_sel)$sigma)^2

MSPE
MS_res
sum(MSPE - MS_res)
sum((housing_mod$Y - predict(fit_sel))^2)
```

```{r}
# Model diagnostics
# -------------------------------
#library(car)
fit <- lm(Y ~ X2 + X5 + X6 + X8 + X9 + X10 + X11 + X12 + X13, data = housing)
# Functional form
par(mfrow = c(2,2), oma = c(1,1,0,0), 
    mar = c(2,2,2,2), tcl = -0.1, mgp = c(1,0,0))
plot(fit$residuals~X2, xlab = "X2", ylab = "Residuals")
abline(h = 0)
plot(fit$residuals~X5, xlab = "X5", ylab = "Residuals")
abline(h = 0)
plot(fit$residuals~X6, xlab = "X6", ylab = "Residuals")
abline(h = 0)
plot(fit$residuals~X8, xlab = "X8", ylab = "Residuals")
abline(h = 0)
plot(fit$residuals~X9, xlab = "X9", ylab = "Residuals")
abline(h = 0)
plot(fit$residuals~X10, xlab = "X10", ylab = "Residuals")
abline(h = 0)
plot(fit$residuals~X11, xlab = "X11", ylab = "Residuals")
abline(h = 0)
plot(fit$residuals~X12, xlab = "X12", ylab = "Residuals")
abline(h = 0)
plot(fit$residuals~X13, xlab = "X13", ylab = "Residuals")
abline(h = 0)
plot(fit$residuals~fit$fitted.values, xlab = "Fitted values", ylab = "Residuals")
abline(h = 0)
par(mfrow = c(1,1))
```

```{r}
# Outlying Y observations
#library(car)
# Statistical test
outlierTest(fit)
# Studentized deleted residuals
t <- rstudent(fit)
alpha <- 0.05
n <- length(Y)
p_prime = length(coef(fit)) 
t_crit <- qt(1-alpha/(2*n),n-p_prime-1)
round(t,2)
t_crit
which(abs(t) > t_crit)
```

```{r}
# Outlying X observations 
Pii <- hatvalues(fit)
round(Pii, 2)
which(Pii > 2*p_prime/n)
which(Pii > 0.5)
```

```{r}
# Influence 
influencePlot(fit,	id.method="identify", 
              main="Influence Plot", 
              sub="Circle size is proportial to Cook's Distance" )
DFFITS <- dffits(fit)
which(DFFITS > 1)
D <- cooks.distance(fit)
which(D > qf(0.2, p_prime, n-p_prime))
DFBETAS <- dfbetas(fit)
head(DFBETAS)
which(DFBETAS > 1)
```